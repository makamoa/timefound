{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpt/data3/KURC/users/makamx0a/venvs/moment/lib/python3.11/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "from momentfm.data.informer_dataset import InformerDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import momentfm\n",
    "from momentfm import MOMENTPipeline\n",
    "from momentfm.utils.masking import Masking\n",
    "from tqdm.auto import tqdm\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from momentfm.utils.utils import control_randomness\n",
    "from momentfm.utils.forecasting_metrics import mse, mae\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\",\n",
    "    model_kwargs={'task_name': 'reconstruction',  # For imputation, we will load MOMENT in `reconstruction` mode\n",
    "                  'freeze_encoder': False,  # Freeze the patch embedding layer\n",
    "                  'freeze_embedder': False,  # Freeze the transformer encoder\n",
    "                  'freeze_head': False,  # The linear forecasting head must be trained\n",
    "                  }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─RevIN: 1-1                             [-1, 5, 512]              --\n",
      "├─Patching: 1-2                          [-1, 5, 64, 8]            --\n",
      "├─PatchEmbedding: 1-3                    [-1, 5, 64, 1024]         --\n",
      "|    └─Linear: 2-1                       [-1, 5, 64, 1024]         8,192\n",
      "|    └─PositionalEmbedding: 2-2          [-1, 64, 1024]            --\n",
      "|    └─Dropout: 2-3                      [-1, 5, 64, 1024]         --\n",
      "├─T5Stack: 1-4                           [[-1, 64, 1024]]          --\n",
      "|    └─Dropout: 2-4                      [-1, 64, 1024]            --\n",
      "|    └─ModuleList: 2                     []                        --\n",
      "|    |    └─T5Block: 3-1                 [-1, 64, 1024]            12,847,616\n",
      "|    |    └─T5Block: 3-2                 [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-3                 [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-4                 [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-5                 [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-6                 [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-7                 [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-8                 [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-9                 [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-10                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-11                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-12                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-13                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-14                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-15                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-16                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-17                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-18                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-19                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-20                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-21                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-22                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-23                [-1, 64, 1024]            12,847,104\n",
      "|    |    └─T5Block: 3-24                [-1, 64, 1024]            12,847,104\n",
      "|    └─T5LayerNorm: 2-5                  [-1, 64, 1024]            1,024\n",
      "|    └─Dropout: 2-6                      [-1, 64, 1024]            --\n",
      "├─PretrainHead: 1-5                      [-1, 5, 512]              --\n",
      "|    └─Dropout: 2-7                      [-1, 5, 64, 1024]         --\n",
      "|    └─Linear: 2-8                       [-1, 5, 64, 8]            8,200\n",
      "├─RevIN: 1-6                             [-1, 5, 512]              --\n",
      "==========================================================================================\n",
      "Total params: 308,348,424\n",
      "Trainable params: 308,348,424\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 649.60\n",
      "==========================================================================================\n",
      "Input size (MB): 1.88\n",
      "Forward/backward pass size (MB): 3.02\n",
      "Params size (MB): 1176.26\n",
      "Estimated Total Size (MB): 1181.15\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─RevIN: 1-1                             [-1, 5, 512]              --\n",
       "├─Patching: 1-2                          [-1, 5, 64, 8]            --\n",
       "├─PatchEmbedding: 1-3                    [-1, 5, 64, 1024]         --\n",
       "|    └─Linear: 2-1                       [-1, 5, 64, 1024]         8,192\n",
       "|    └─PositionalEmbedding: 2-2          [-1, 64, 1024]            --\n",
       "|    └─Dropout: 2-3                      [-1, 5, 64, 1024]         --\n",
       "├─T5Stack: 1-4                           [[-1, 64, 1024]]          --\n",
       "|    └─Dropout: 2-4                      [-1, 64, 1024]            --\n",
       "|    └─ModuleList: 2                     []                        --\n",
       "|    |    └─T5Block: 3-1                 [-1, 64, 1024]            12,847,616\n",
       "|    |    └─T5Block: 3-2                 [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-3                 [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-4                 [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-5                 [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-6                 [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-7                 [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-8                 [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-9                 [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-10                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-11                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-12                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-13                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-14                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-15                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-16                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-17                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-18                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-19                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-20                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-21                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-22                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-23                [-1, 64, 1024]            12,847,104\n",
       "|    |    └─T5Block: 3-24                [-1, 64, 1024]            12,847,104\n",
       "|    └─T5LayerNorm: 2-5                  [-1, 64, 1024]            1,024\n",
       "|    └─Dropout: 2-6                      [-1, 64, 1024]            --\n",
       "├─PretrainHead: 1-5                      [-1, 5, 512]              --\n",
       "|    └─Dropout: 2-7                      [-1, 5, 64, 1024]         --\n",
       "|    └─Linear: 2-8                       [-1, 5, 64, 8]            8,200\n",
       "├─RevIN: 1-6                             [-1, 5, 512]              --\n",
       "==========================================================================================\n",
       "Total params: 308,348,424\n",
       "Trainable params: 308,348,424\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 649.60\n",
       "==========================================================================================\n",
       "Input size (MB): 1.88\n",
       "Forward/backward pass size (MB): 3.02\n",
       "Params size (MB): 1176.26\n",
       "Estimated Total Size (MB): 1181.15\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_data=inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbranching\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcol_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcol_width\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdepth\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtypes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorchsummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_statistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelStatistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Summarize the given PyTorch model. Summarized information includes:\n",
      "    1) Layer names,\n",
      "    2) input/output shapes,\n",
      "    3) kernel shape,\n",
      "    4) # of parameters,\n",
      "    5) # of operations (Mult-Adds)\n",
      "\n",
      "Args:\n",
      "    model (nn.Module):\n",
      "            PyTorch model to summarize. The model should be fully in either train()\n",
      "            or eval() mode. If layers are not all in the same mode, running summary\n",
      "            may have side effects on batchnorm or dropout statistics. If you\n",
      "            encounter an issue with this, please open a GitHub issue.\n",
      "\n",
      "    input_data (Sequence of Sizes or Tensors):\n",
      "            Example input tensor of the model (dtypes inferred from model input).\n",
      "            - OR -\n",
      "            Shape of input data as a List/Tuple/torch.Size\n",
      "            (dtypes must match model input, default is FloatTensors).\n",
      "            You should NOT include batch size in the tuple.\n",
      "            - OR -\n",
      "            If input_data is not provided, no forward pass through the network is\n",
      "            performed, and the provided model information is limited to layer names.\n",
      "            Default: None\n",
      "\n",
      "    batch_dim (int):\n",
      "            Batch_dimension of input data. If batch_dim is None, the input data\n",
      "            is assumed to contain the batch dimension.\n",
      "            WARNING: in a future version, the default will change to None.\n",
      "            Default: 0\n",
      "\n",
      "    branching (bool):\n",
      "            Whether to use the branching layout for the printed output.\n",
      "            Default: True\n",
      "\n",
      "    col_names (Iterable[str]):\n",
      "            Specify which columns to show in the output. Currently supported:\n",
      "            (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\")\n",
      "            If input_data is not provided, only \"num_params\" is used.\n",
      "            Default: (\"output_size\", \"num_params\")\n",
      "\n",
      "    col_width (int):\n",
      "            Width of each column.\n",
      "            Default: 25\n",
      "\n",
      "    depth (int):\n",
      "            Number of nested layers to traverse (e.g. Sequentials).\n",
      "            Default: 3\n",
      "\n",
      "    device (torch.Device):\n",
      "            Uses this torch device for model and input_data.\n",
      "            If not specified, uses result of torch.cuda.is_available().\n",
      "            Default: None\n",
      "\n",
      "    dtypes (List[torch.dtype]):\n",
      "            For multiple inputs, specify the size of both inputs, and\n",
      "            also specify the types of each parameter here.\n",
      "            Default: None\n",
      "\n",
      "    verbose (int):\n",
      "            0 (quiet): No output\n",
      "            1 (default): Print model summary\n",
      "            2 (verbose): Show weight and bias layers in full detail\n",
      "            Default: 1\n",
      "\n",
      "    *args, **kwargs:\n",
      "            Other arguments used in `model.forward` function.\n",
      "\n",
      "Return:\n",
      "    ModelStatistics object\n",
      "            See torchsummary/model_statistics.py for more information.\n",
      "\u001b[0;31mFile:\u001b[0m      /gpt/data3/KURC/users/makamx0a/venvs/moment/lib/python3.11/site-packages/torchsummary/torchsummary.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "summary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "seed=13\n",
    "epochs = 3\n",
    "lr = 1e-4\n",
    "batch_size = 192\n",
    "grad_accum_step = 1\n",
    "use_amp = True\n",
    "use_tensorcore = True\n",
    "autotune = True\n",
    "use_fused = True # False for quick start/debug mode\n",
    "zero_stage = 2\n",
    "data_stride_len = 512\n",
    "mask_ratio = 0.3\n",
    "dtype = torch.float32\n",
    "amp_dtype = torch.bfloat16  # use float16 for V100 and bfloat16 for A100\n",
    "# amp_dtype = torch.float16  # use float16 for V100 and bfloat16 for A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_zero_config = {\n",
    "  \"train_batch_size\": batch_size,\n",
    "  \"gradient_accumulation_steps\": grad_accum_step,\n",
    "  \"optimizer\": {\n",
    "    \"type\": \"Adam\",\n",
    "    \"params\": {\n",
    "      \"lr\": lr\n",
    "    }\n",
    "  },\n",
    "  \"fp16\": {\n",
    "    \"enabled\": amp_dtype == torch.float16 and use_amp\n",
    "  },\n",
    "  \"bf16\": {\n",
    "   \"enabled\": amp_dtype == torch.bfloat16 and use_amp\n",
    "  },\n",
    "  \"zero_optimization\": {\n",
    "    \"stage\": zero_stage\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\",\n",
    "    model_kwargs={'task_name': 'reconstruction', # For imputation, we will load MOMENT in `reconstruction` mode\n",
    "                   'freeze_encoder': False, # Freeze the patch embedding layer\n",
    "                   'freeze_embedder': False, # Freeze the transformer encoder\n",
    "                   'freeze_head': False, # The linear forecasting head must be trained\n",
    "                 }\n",
    ")\n",
    "\n",
    "mask_generator = Masking(mask_ratio=mask_ratio) # Mask 30% of patches randomly \n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "world_size = torch.cuda.device_count()\n",
    "model = model.to(rank, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch compile needs some times...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ecc_17/makamx0a/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ecc_17/makamx0a/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "/gpt/data3/KURC/users/makamx0a/venvs/moment/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load fused_adam op: 0.0867621898651123 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module fused_adam...\n"
     ]
    }
   ],
   "source": [
    "# Optimize Mean Squarred Error using your favourite optimizer\n",
    "criterion = torch.nn.MSELoss() \n",
    "if use_fused:\n",
    "    print(\"Torch compile needs some times...\")\n",
    "    model = torch.compile(model)\n",
    "    optimizer = FusedAdam(model.parameters(), lr=lr)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tensor core\n",
    "if use_tensorcore:\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataset\n",
    "class WellLogDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 root_dir, \n",
    "                 task_name: str = \"imputation\", \n",
    "                 data_split: str = \"train\", \n",
    "                 few_shot: int = 5, \n",
    "                 forecast_horizon: int = 192\n",
    "                ):\n",
    "        self.seq_len = 512\n",
    "        self.root_dir = root_dir\n",
    "        self.task_name = task_name\n",
    "        self.data_split = data_split\n",
    "        self.few_shot = few_shot\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        with open(root_dir + 'dict_tokens.json', 'r') as file:\n",
    "            self.mapping = json.load(file)\n",
    "        self._read_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def _get_borders(self):\n",
    "        train_mapping = dict(itertools.islice(self.mapping.items(), self.few_shot))\n",
    "        test_mapping = dict(itertools.islice(self.mapping.items(), self.few_shot, len(self.mapping)))\n",
    "        return train_mapping, test_mapping\n",
    "\n",
    "    def _read_data(self):\n",
    "        train_mapping, test_mapping = self._get_borders()\n",
    "\n",
    "        if self.data_split == \"train\":\n",
    "               self.files = [f for f in train_mapping.values()]\n",
    "        elif self.data_split == \"test\":\n",
    "               self.files = [f for f in test_mapping.values()]\n",
    "        self.length_timeseries = len(self.files)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx]\n",
    "        input_mask = np.ones(self.seq_len)\n",
    "        data_dict = torch.load(file_name)\n",
    "        if self.task_name == 'imputation':\n",
    "            return data_dict['input'].T, input_mask\n",
    "        elif self.task_name == 'forecast':\n",
    "            return  data_dict['input'].T, data_dict['label'].T[:, :self.forecast_horizon], input_mask\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "global_configs = Config('../.config/settings.yaml')\n",
    "ARAMCO_LOGS = os.path.join(global_configs.data, 'alphas', 'tokenized/logs_tokenized/data_processed_512_standard_Aramco/')\n",
    "root_dir = ARAMCO_LOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = torch.cuda.device_count()\n",
    "train_dataset = WellLogDataset(root_dir, task_name='forecast', data_split=\"train\",  few_shot=14400)\n",
    "#train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(train_loader)\n",
    "inp, labels, mask = next(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([192, 5, 512]), torch.Size([192, 5, 192]), torch.Size([192, 512]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape, labels.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

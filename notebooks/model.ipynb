{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 61\u001b[0m\n\u001b[1;32m     55\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(rank, dtype)\n\u001b[1;32m     57\u001b[0m \u001b[39m# # Initialize the process group\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# dist.init_process_group(backend='nccl', init_method='env://')\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39m# Wrap the model for distributed training\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mparallel\u001b[39m.\u001b[39;49mDistributedDataParallel(model, device_ids\u001b[39m=\u001b[39;49m[rank])\n\u001b[1;32m     63\u001b[0m \u001b[39m# Optimize Mean Squarred Error using your favourite optimizer\u001b[39;00m\n\u001b[1;32m     64\u001b[0m criterion \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mMSELoss()\n",
      "File \u001b[0;32m/gpt/data3/KURC/users/makamx0a/venvs/moment/lib/python3.11/site-packages/torch/nn/parallel/distributed.py:731\u001b[0m, in \u001b[0;36mDistributedDataParallel.__init__\u001b[0;34m(self, module, device_ids, output_device, dim, broadcast_buffers, process_group, bucket_cap_mb, find_unused_parameters, check_reduction, gradient_as_bucket_view, static_graph, delay_all_reduce_named_params, param_to_hook_all_reduce, mixed_precision, device_mesh)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    728\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot specify both process_group and device_mesh arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    730\u001b[0m \u001b[39melif\u001b[39;00m process_group \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m device_mesh \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 731\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_group \u001b[39m=\u001b[39m _get_default_group()\n\u001b[1;32m    732\u001b[0m \u001b[39melif\u001b[39;00m device_mesh \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    733\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_group \u001b[39m=\u001b[39m process_group\n",
      "File \u001b[0;32m/gpt/data3/KURC/users/makamx0a/venvs/moment/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:1008\u001b[0m, in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get the default process group created by init_process_group.\"\"\"\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_initialized():\n\u001b[0;32m-> 1008\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1009\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDefault process group has not been initialized, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1010\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mplease make sure to call init_process_group.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1012\u001b[0m \u001b[39mreturn\u001b[39;00m not_none(GroupMember\u001b[39m.\u001b[39mWORLD)\n",
      "\u001b[0;31mValueError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "from momentfm.data.informer_dataset import InformerDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import momentfm\n",
    "from momentfm import MOMENTPipeline\n",
    "from momentfm.utils.masking import Masking\n",
    "from tqdm.auto import tqdm\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from momentfm.utils.utils import control_randomness\n",
    "from momentfm.utils.forecasting_metrics import mse, mae\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters\n",
    "seed = 13\n",
    "epochs = 3\n",
    "lr = 1e-4\n",
    "batch_size = 192\n",
    "grad_accum_step = 1\n",
    "use_amp = True\n",
    "use_tensorcore = True\n",
    "autotune = True\n",
    "use_fused = True  # False for quick start/debug mode\n",
    "data_stride_len = 512\n",
    "mask_ratio = 0.3\n",
    "dtype = torch.float32\n",
    "amp_dtype = torch.bfloat16  # use float16 for V100 and bfloat16 for A100\n",
    "# amp_dtype = torch.float16  # use float16 for V100 and bfloat16 for A100\n",
    "\n",
    "control_randomness(seed=seed)  # Set random seeds for PyTorch, Numpy etc.\n",
    "\n",
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\",\n",
    "    model_kwargs={'task_name': 'reconstruction',  # For imputation, we will load MOMENT in `reconstruction` mode\n",
    "                  'freeze_encoder': False,  # Freeze the patch embedding layer\n",
    "                  'freeze_embedder': False,  # Freeze the transformer encoder\n",
    "                  'freeze_head': False,  # The linear forecasting head must be trained\n",
    "                  }\n",
    ")\n",
    "\n",
    "mask_generator = Masking(mask_ratio=mask_ratio)  # Mask 30% of patches randomly\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
    "world_size = int(os.environ.get(\"WORLD_SIZE\", -1))\n",
    "\n",
    "model = model.to(rank, dtype)\n",
    "\n",
    "# Initialize the process group\n",
    "dist.init_process_group(backend='nccl', init_method='env://')\n",
    "\n",
    "# Wrap the model for distributed training\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[rank])\n",
    "\n",
    "# Optimize Mean Squarred Error using your favourite optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "if use_fused:\n",
    "    print(\"Torch compile needs some times...\")\n",
    "    model = torch.compile(model)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Number of parameters in the encoder\n",
    "if rank == 0:\n",
    "    print(f\"Number of parameters: {num_params}\")\n",
    "\n",
    "# Dataset\n",
    "class WellLogDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 root_dir,\n",
    "                 task_name: str = \"imputation\",\n",
    "                 data_split: str = \"train\",\n",
    "                 few_shot: int = 5,\n",
    "                 forecast_horizon: int = 192\n",
    "                 ):\n",
    "        self.seq_len = 512\n",
    "        self.root_dir = root_dir\n",
    "        self.task_name = task_name\n",
    "        self.data_split = data_split\n",
    "        self.few_shot = few_shot\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        with open(root_dir + 'dict_tokens.json', 'r') as file:\n",
    "            self.mapping = json.load(file)\n",
    "        self._read_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def _get_borders(self):\n",
    "        train_mapping = dict(itertools.islice(self.mapping.items(), self.few_shot))\n",
    "        test_mapping = dict(itertools.islice(self.mapping.items(), self.few_shot, len(self.mapping)))\n",
    "        return train_mapping, test_mapping\n",
    "\n",
    "    def _read_data(self):\n",
    "        train_mapping, test_mapping = self._get_borders()\n",
    "\n",
    "        if self.data_split == \"train\":\n",
    "            self.files = [f for f in train_mapping.values()]\n",
    "        elif self.data_split == \"test\":\n",
    "            self.files = [f for f in test_mapping.values()]\n",
    "        self.length_timeseries = len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx]\n",
    "        input_mask = np.ones(self.seq_len)\n",
    "        data_dict = torch.load(file_name)\n",
    "        if self.task_name == 'imputation':\n",
    "            return data_dict['input'].T, input_mask\n",
    "        elif self.task_name == 'forecast':\n",
    "            return data_dict['input'].T, data_dict['label'].T[:, :self.forecast_horizon], input_mask\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "from config import Config\n",
    "global_configs = Config('../.config/settings.yaml')\n",
    "ARAMCO_LOGS = os.path.join(global_configs.data, 'alphas', 'tokenized/logs_tokenized/data_processed_512_standard_Aramco/')\n",
    "root_dir = ARAMCO_LOGS\n",
    "\n",
    "train_dataset = WellLogDataset(root_dir, task_name='imputation', data_split=\"train\", few_shot=14400)\n",
    "train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=rank, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "\n",
    "test_dataset = WellLogDataset(root_dir, task_name='imputation', data_split=\"test\", few_shot=14400)\n",
    "test_sampler = DistributedSampler(test_dataset, num_replicas=world_size, rank=rank, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "# use tensor core\n",
    "if use_tensorcore:\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# training loop\n",
    "loss_val = []\n",
    "for epoch in range(epochs):\n",
    "    for step, (batch_x, batch_masks) in enumerate(tqdm(train_loader, total=len(train_loader))):\n",
    "        batch_x, batch_masks = batch_x.to(rank, dtype), batch_masks.to(rank)\n",
    "        n_channels = batch_x.shape[1]\n",
    "\n",
    "        # Reshape to [batch_size * n_channels, 1, window_size]\n",
    "        batch_x = batch_x.reshape((-1, 1, data_stride_len))\n",
    "\n",
    "        batch_masks = batch_masks.to(rank).long()\n",
    "        batch_masks = batch_masks.repeat_interleave(n_channels, axis=0)\n",
    "\n",
    "        # Randomly mask some patches of data\n",
    "        mask = mask_generator.generate_mask(\n",
    "            x=batch_x, input_mask=batch_masks).to(rank).long()\n",
    "\n",
    "        if use_amp:\n",
    "            with autocast(dtype=amp_dtype):\n",
    "                output = model(batch_x, input_mask=batch_masks, mask=mask)\n",
    "        else:\n",
    "            output = model(batch_x, input_mask=batch_masks, mask=mask)\n",
    "\n",
    "        # Compute loss\n",
    "        recon_loss = criterion(output.reconstruction, batch_x)\n",
    "        observed_mask = batch_masks * (1 - mask)\n",
    "        masked_loss = observed_mask * recon_loss\n",
    "\n",
    "        loss = masked_loss.nansum() / (observed_mask.nansum() + 1e-7)\n",
    "\n",
    "        if rank == 0:\n",
    "            tqdm.write(f\"loss: {loss.item()}\")\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        trues, preds, masks = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_x_val, batch_masks_val in tqdm(test_loader, total=len(test_loader)):\n",
    "                trues.append(batch_x_val.numpy())\n",
    "\n",
    "                batch_x_val = batch_x_val.to(rank).float()\n",
    "                n_channels_val = batch_x_val.shape[1]\n",
    "\n",
    "                # Reshape to [batch_size * n_channels, 1, window_size]\n",
    "                batch_x_val = batch_x_val.reshape((-1, 1, 512))\n",
    "\n",
    "                batch_masks_val = batch_masks_val.to(rank).long()\n",
    "                batch_masks_val = batch_masks_val.repeat_interleave(n_channels_val, axis=0)\n",
    "\n",
    "                mask_val = mask_generator.generate_mask(\n",
    "                    x=batch_x_val, input_mask=batch_masks_val).to(rank).long()\n",
    "\n",
    "                if use_amp:\n",
    "                    with autocast(dtype=amp_dtype):\n",
    "                        output_val = model(batch_x_val, input_mask=batch_masks_val, mask=mask_val)  # [batch_size, n_channels, window_size]\n",
    "                else:\n",
    "                    output_val = model(batch_x_val, input_mask=batch_masks_val, mask=mask_val)  # [batch_size, n_channels, window_size]\n",
    "\n",
    "                reconstruction_val = output_val.reconstruction.detach().cpu().numpy()\n",
    "                mask_val = mask_val.detach().squeeze().cpu().numpy()\n",
    "\n",
    "                # Reshape back to [batch_size, n_channels, window_size]\n",
    "                reconstruction_val = reconstruction_val.reshape((-1, n_channels, 512))\n",
    "                mask_val = mask_val.reshape((-1, n_channels, 512))\n",
    "\n",
    "                preds.append(reconstruction_val)\n",
    "                masks.append(mask_val)\n",
    "\n",
    "        preds = np.concatenate(preds)\n",
    "        trues = np.concatenate(trues)\n",
    "        masks = np.concatenate(masks)\n",
    "        loss_val.append(mse(y=trues.astype(np.float32)[masks == 0], y_hat=preds.astype(np.float32)[masks == 0], reduction='mean'))\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "if rank == 0:\n",
    "    torch.save(model.state_dict(), \"/gpt/data3/KURC/users/kovaledx/src/distributed/saved/moment_model.pt\")\n",
    "    print(f\"Mean Squarred Error (MSE)={mse(y=trues[masks == 0], y_hat=preds[masks == 0], reduction='mean')}\")\n",
    "    print(f\"Mean Absolute Error (MAE)={mae(y=trues[masks == 0], y_hat=preds[masks == 0], reduction='mean')}\")\n",
    "\n",
    "    for col in range(5):\n",
    "        print(f\"Mean Squarred Error (MSE)={mse(y=trues[:, col, :][masks[:, col, :] == 0], y_hat=preds[:, col, :][masks[:, col, :] == 0], reduction='mean')}\")\n",
    "        print(f\"Mean Abs Error (MAE)={mae(y=trues[:, col, :][masks[:, col, :] == 0], y_hat=preds[:, col, :][masks[:, col, :] == 0], reduction='mean')}\")\n",
    "        n_channels = trues.shape[1]\n",
    "        idx = np.random.randint(trues.shape[0])\n",
    "        colms = [\"GR\", \"RDEP\", \"DTC\", \"NPHI\", \"RHOB\"]\n",
    "\n",
    "        fig, axs = plt.subplots(n_channels * 2, 1, figsize=(10, 2 * n_channels))\n",
    "\n",
    "        for channel_idx in range(n_channels):\n",
    "            axs[channel_idx * 2].set_title(f\"Patch={idx}, Channel={colms[channel_idx]}\")\n",
    "            axs[channel_idx * 2].plot(trues[idx, channel_idx, :].squeeze(), label='Ground Truth', c='darkblue')\n",
    "            axs[channel_idx * 2].plot(preds[idx, channel_idx, :].squeeze(), label='Predictions', c='red')\n",
    "            axs[channel_idx * 2].legend(fontsize=6)\n",
    "            axs[channel_idx * 2 + 1].imshow(np.tile(masks[np.newaxis, idx, channel_idx], reps=(8, 1)), cmap='winter')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('zero5well_50_30_all.png')\n",
    "        # plt.show()\n",
    "\n",
    "# Clean up\n",
    "dist.destroy_process_group()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "seed=13\n",
    "epochs = 3\n",
    "lr = 1e-4\n",
    "batch_size = 192\n",
    "grad_accum_step = 1\n",
    "use_amp = True\n",
    "use_tensorcore = True\n",
    "autotune = True\n",
    "use_fused = True # False for quick start/debug mode\n",
    "zero_stage = 2\n",
    "data_stride_len = 512\n",
    "mask_ratio = 0.3\n",
    "dtype = torch.float32\n",
    "amp_dtype = torch.bfloat16  # use float16 for V100 and bfloat16 for A100\n",
    "# amp_dtype = torch.float16  # use float16 for V100 and bfloat16 for A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_zero_config = {\n",
    "  \"train_batch_size\": batch_size,\n",
    "  \"gradient_accumulation_steps\": grad_accum_step,\n",
    "  \"optimizer\": {\n",
    "    \"type\": \"Adam\",\n",
    "    \"params\": {\n",
    "      \"lr\": lr\n",
    "    }\n",
    "  },\n",
    "  \"fp16\": {\n",
    "    \"enabled\": amp_dtype == torch.float16 and use_amp\n",
    "  },\n",
    "  \"bf16\": {\n",
    "   \"enabled\": amp_dtype == torch.bfloat16 and use_amp\n",
    "  },\n",
    "  \"zero_optimization\": {\n",
    "    \"stage\": zero_stage\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\",\n",
    "    model_kwargs={'task_name': 'reconstruction', # For imputation, we will load MOMENT in `reconstruction` mode\n",
    "                   'freeze_encoder': False, # Freeze the patch embedding layer\n",
    "                   'freeze_embedder': False, # Freeze the transformer encoder\n",
    "                   'freeze_head': False, # The linear forecasting head must be trained\n",
    "                 }\n",
    ")\n",
    "\n",
    "mask_generator = Masking(mask_ratio=mask_ratio) # Mask 30% of patches randomly \n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "world_size = torch.cuda.device_count()\n",
    "model = model.to(rank, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch compile needs some times...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ecc_17/makamx0a/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ecc_17/makamx0a/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "/gpt/data3/KURC/users/makamx0a/venvs/moment/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load fused_adam op: 0.0867621898651123 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module fused_adam...\n"
     ]
    }
   ],
   "source": [
    "# Optimize Mean Squarred Error using your favourite optimizer\n",
    "criterion = torch.nn.MSELoss() \n",
    "if use_fused:\n",
    "    print(\"Torch compile needs some times...\")\n",
    "    model = torch.compile(model)\n",
    "    optimizer = FusedAdam(model.parameters(), lr=lr)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tensor core\n",
    "if use_tensorcore:\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataset\n",
    "class WellLogDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 root_dir, \n",
    "                 task_name: str = \"imputation\", \n",
    "                 data_split: str = \"train\", \n",
    "                 few_shot: int = 5, \n",
    "                 forecast_horizon: int = 192\n",
    "                ):\n",
    "        self.seq_len = 512\n",
    "        self.root_dir = root_dir\n",
    "        self.task_name = task_name\n",
    "        self.data_split = data_split\n",
    "        self.few_shot = few_shot\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        with open(root_dir + 'dict_tokens.json', 'r') as file:\n",
    "            self.mapping = json.load(file)\n",
    "        self._read_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def _get_borders(self):\n",
    "        train_mapping = dict(itertools.islice(self.mapping.items(), self.few_shot))\n",
    "        test_mapping = dict(itertools.islice(self.mapping.items(), self.few_shot, len(self.mapping)))\n",
    "        return train_mapping, test_mapping\n",
    "\n",
    "    def _read_data(self):\n",
    "        train_mapping, test_mapping = self._get_borders()\n",
    "\n",
    "        if self.data_split == \"train\":\n",
    "               self.files = [f for f in train_mapping.values()]\n",
    "        elif self.data_split == \"test\":\n",
    "               self.files = [f for f in test_mapping.values()]\n",
    "        self.length_timeseries = len(self.files)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx]\n",
    "        input_mask = np.ones(self.seq_len)\n",
    "        data_dict = torch.load(file_name)\n",
    "        if self.task_name == 'imputation':\n",
    "            return data_dict['input'].T, input_mask\n",
    "        elif self.task_name == 'forecast':\n",
    "            return  data_dict['input'].T, data_dict['label'].T[:, :self.forecast_horizon], input_mask\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "global_configs = Config('../.config/settings.yaml')\n",
    "ARAMCO_LOGS = os.path.join(global_configs.data, 'alphas', 'tokenized/logs_tokenized/data_processed_512_standard_Aramco/')\n",
    "root_dir = ARAMCO_LOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset \u001b[39m=\u001b[39m WellLogDataset(root_dir, task_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimputation\u001b[39m\u001b[39m'\u001b[39m, data_split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,  few_shot\u001b[39m=\u001b[39m\u001b[39m14400\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m train_sampler \u001b[39m=\u001b[39m DistributedSampler(train_dataset, num_replicas\u001b[39m=\u001b[39;49mworld_size, shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      3\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39mbatch_size, sampler\u001b[39m=\u001b[39mtrain_sampler)\n",
      "File \u001b[0;32m/gpt/data3/KURC/users/makamx0a/venvs/moment/lib/python3.11/site-packages/torch/utils/data/distributed.py:72\u001b[0m, in \u001b[0;36mDistributedSampler.__init__\u001b[0;34m(self, dataset, num_replicas, rank, shuffle, seed, drop_last)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dist\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m     71\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mRequires distributed package to be available\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m     rank \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39;49mget_rank()\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m num_replicas \u001b[39mor\u001b[39;00m rank \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid rank \u001b[39m\u001b[39m{\u001b[39;00mrank\u001b[39m}\u001b[39;00m\u001b[39m, rank should be in the interval [0, \u001b[39m\u001b[39m{\u001b[39;00mnum_replicas\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/gpt/data3/KURC/users/makamx0a/venvs/moment/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:1746\u001b[0m, in \u001b[0;36mget_rank\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[39mif\u001b[39;00m _rank_not_in_group(group):\n\u001b[1;32m   1744\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m-> 1746\u001b[0m default_pg \u001b[39m=\u001b[39m _get_default_group()\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m group \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m group \u001b[39mis\u001b[39;00m GroupMember\u001b[39m.\u001b[39mWORLD:\n\u001b[1;32m   1748\u001b[0m     \u001b[39mreturn\u001b[39;00m default_pg\u001b[39m.\u001b[39mrank()\n",
      "File \u001b[0;32m/gpt/data3/KURC/users/makamx0a/venvs/moment/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:1008\u001b[0m, in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get the default process group created by init_process_group.\"\"\"\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_initialized():\n\u001b[0;32m-> 1008\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1009\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDefault process group has not been initialized, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1010\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mplease make sure to call init_process_group.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1012\u001b[0m \u001b[39mreturn\u001b[39;00m not_none(GroupMember\u001b[39m.\u001b[39mWORLD)\n",
      "\u001b[0;31mValueError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "world_size = torch.cuda.device_count()\n",
    "train_dataset = WellLogDataset(root_dir, task_name='imputation', data_split=\"train\",  few_shot=14400)\n",
    "train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mDistributedSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_replicas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdrop_last\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Sampler that restricts data loading to a subset of the dataset.\n",
      "\n",
      "It is especially useful in conjunction with\n",
      ":class:`torch.nn.parallel.DistributedDataParallel`. In such a case, each\n",
      "process can pass a :class:`~torch.utils.data.DistributedSampler` instance as a\n",
      ":class:`~torch.utils.data.DataLoader` sampler, and load a subset of the\n",
      "original dataset that is exclusive to it.\n",
      "\n",
      ".. note::\n",
      "    Dataset is assumed to be of constant size and that any instance of it always\n",
      "    returns the same elements in the same order.\n",
      "\n",
      "Args:\n",
      "    dataset: Dataset used for sampling.\n",
      "    num_replicas (int, optional): Number of processes participating in\n",
      "        distributed training. By default, :attr:`world_size` is retrieved from the\n",
      "        current distributed group.\n",
      "    rank (int, optional): Rank of the current process within :attr:`num_replicas`.\n",
      "        By default, :attr:`rank` is retrieved from the current distributed\n",
      "        group.\n",
      "    shuffle (bool, optional): If ``True`` (default), sampler will shuffle the\n",
      "        indices.\n",
      "    seed (int, optional): random seed used to shuffle the sampler if\n",
      "        :attr:`shuffle=True`. This number should be identical across all\n",
      "        processes in the distributed group. Default: ``0``.\n",
      "    drop_last (bool, optional): if ``True``, then the sampler will drop the\n",
      "        tail of the data to make it evenly divisible across the number of\n",
      "        replicas. If ``False``, the sampler will add extra indices to make\n",
      "        the data evenly divisible across the replicas. Default: ``False``.\n",
      "\n",
      ".. warning::\n",
      "    In distributed mode, calling the :meth:`set_epoch` method at\n",
      "    the beginning of each epoch **before** creating the :class:`DataLoader` iterator\n",
      "    is necessary to make shuffling work properly across multiple epochs. Otherwise,\n",
      "    the same ordering will be always used.\n",
      "\n",
      "Example::\n",
      "\n",
      "    >>> # xdoctest: +SKIP\n",
      "    >>> sampler = DistributedSampler(dataset) if is_distributed else None\n",
      "    >>> loader = DataLoader(dataset, shuffle=(sampler is None),\n",
      "    ...                     sampler=sampler)\n",
      "    >>> for epoch in range(start_epoch, n_epochs):\n",
      "    ...     if is_distributed:\n",
      "    ...         sampler.set_epoch(epoch)\n",
      "    ...     train(loader)\n",
      "\u001b[0;31mFile:\u001b[0m           /gpt/data3/KURC/users/makamx0a/venvs/moment/lib/python3.11/site-packages/torch/utils/data/distributed.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "DistributedSampler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
